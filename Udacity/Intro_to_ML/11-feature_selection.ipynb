{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 11: Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy\n",
    "numpy.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### The words (features) and authors (labels), already largely processed.\n",
    "### These files should have been created from the previous (Lesson 10)\n",
    "### mini-project.\n",
    "words_file = \"../text_learning/your_word_data.pkl\" \n",
    "authors_file = \"../text_learning/your_email_authors.pkl\"\n",
    "word_data = pickle.load( open(words_file, \"r\"))\n",
    "authors = pickle.load( open(authors_file, \"r\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### test_size is the percentage of events assigned to the test set (the\n",
    "### remainder go into training)\n",
    "### feature matrices changed to dense representations for compatibility with\n",
    "### classifier functions in versions 0.15.2 and earlier\n",
    "from sklearn import cross_validation\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(word_data, authors, test_size=0.1, random_state=42)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                             stop_words='english')\n",
    "features_train = vectorizer.fit_transform(features_train)\n",
    "features_test  = vectorizer.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### a classic way to overfit is to use a small number\n",
    "### of data points and a large number of features;\n",
    "### train on only 150 events to put ourselves in this regime\n",
    "features_train = features_train[:150]\n",
    "labels_train   = labels_train[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 37860)\n",
      "1.0\n",
      "0.820819112628\n"
     ]
    }
   ],
   "source": [
    "### your code goes here\n",
    "print features_train.shape\n",
    "\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(features_train, labels_train)\n",
    "print clf.score(features_train, labels_train)\n",
    "print clf.score(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Whatâ€™s the importance of the most important feature? What is the number of this feature? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: This had to be run four times. \n",
    "\n",
    "1st run: sshacklensf \n",
    "\n",
    "I then went back to the previous lesson, removed sshacklensf from the word list and rerun the code below.\n",
    "\n",
    "2nd run: sshacklmsncom (this seems to be not the one that they were looking for though...)\n",
    "\n",
    "Again: I went back and removed sshacklmsncom and rerun.\n",
    "\n",
    "3rd run: cgermannsf (this was the one that they were looking for before strangely enough)\n",
    "\n",
    "Finally, we end up with houetect being the most important word, not an obvious signature, so we can leave it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21323 0.363636363636\n"
     ]
    }
   ],
   "source": [
    "outlier_threshold = 0.2\n",
    "for i, importance in enumerate(clf.feature_importances_):\n",
    "    if importance > outlier_threshold:\n",
    "        print i, importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the word causing most of the discrimination?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'houectect'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[21323]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
